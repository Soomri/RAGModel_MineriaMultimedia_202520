{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "012ff87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Clave cargada: True\n",
      "‚úÖ Project root: c:\\Users\\USER\\RAGModel_MineriaMultimedia_202520\n",
      "üìÑ Total chunks cargados: 66\n",
      "‚úÖ √çndice TF-IDF recreado: 66 documentos, 1538 features\n",
      "\n",
      "üîç Consultas definidas: 2\n",
      "\n",
      "ü§ñ Generando ground truth autom√°tico...\n",
      "Query 1: 3 chunks relevantes\n",
      "Query 2: 3 chunks relevantes\n",
      "Chunks originales: 28\n",
      "Chunks deduplicados: 28\n",
      "Features TF-IDF: 4978\n",
      "\n",
      "################################################################################\n",
      "# PIPELINE MODEL C: CHUNKING OPTIMIZADO + DEDUPLICACI√ìN\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üìÇ CARGANDO CHUNKS PREPROCESADOS\n",
      "================================================================================\n",
      "üìÅ Carpeta: c:\\Users\\USER\\RAGModel_MineriaMultimedia_202520\\data\\preprocessed\\processed_400_100\n",
      "‚úÖ Cargados 28 chunks\n",
      "üìä Configuraci√≥n: processed_400_100\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üß© DEDUPLICACI√ìN DE CHUNKS\n",
      "================================================================================\n",
      "üìä Chunks originales: 28\n",
      "üéØ Umbral de similitud: 0.85\n",
      "‚öôÔ∏è Calculando similitudes...\n",
      "‚úÖ Deduplicaci√≥n completada\n",
      "üìâ Chunks eliminados: 0\n",
      "üìä Chunks √∫nicos: 28/28\n",
      "üìà Reducci√≥n: 0.0%\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîß CREACI√ìN DE √çNDICE TF-IDF\n",
      "================================================================================\n",
      "‚úÖ √çndice creado\n",
      "üìä Documentos: 28\n",
      "üìä Features: 4977\n",
      "================================================================================\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# ‚úÖ PIPELINE COMPLETADO\n",
      "################################################################################\n",
      "üìä Resumen:\n",
      "  ‚Ä¢ Chunks originales:   28\n",
      "  ‚Ä¢ Chunks deduplicados: 28\n",
      "  ‚Ä¢ Reducci√≥n:           0.0%\n",
      "  ‚Ä¢ Features TF-IDF:     4977\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîé CONSULTA: 'Who saves Bella from the van?'\n",
      "================================================================================\n",
      "\n",
      "üèÜ RANK 1 | Score: 0.0854\n",
      "üìö Libro: data_summary\n",
      "üìÑ Chunk #1\n",
      "üìè Palabras: 400\n",
      "üìù Texto: 1 Bella Swan moves from Phoenix, Arizona to the small town of Forks, Washington, to live with her father, Charlie. She soon notices the mysterious Cullen family at school, who seem pale, beautiful, and distant from everyone else. 2 Edward Cullen, one of the Cullens, saves Bella from being crushed by...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 2 | Score: 0.0256\n",
      "üìö Libro: twilight\n",
      "üìÑ Chunk #1\n",
      "üìè Palabras: 400\n",
      "üìù Texto: Isabella \"Bella\" Marie Swan moves from the ever sunny Phoenix, Arizona to rainy Forks, Washington to live with her father, Charlie, to allow her mother Ren√©e to travel with her new husband, Phil Dwyer, who is a minor league baseball star. Even though Bella never had many friends in Phoenix, she quic...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 3 | Score: 0.0000\n",
      "üìö Libro: twilight\n",
      "üìÑ Chunk #2\n",
      "üìè Palabras: 400\n",
      "üìù Texto: believes that they are vampires, though he doesn't think so. During a trip to Port Angeles, Edward rescues her again, this time from a band of serial rapists and killers. Bella asks him if what Jacob said about his family is true. Edward admits that he and his family are vampires, but says that he a...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 4 | Score: 0.0000\n",
      "üìö Libro: twilight\n",
      "üìÑ Chunk #3\n",
      "üìè Palabras: 129\n",
      "üìù Texto: it too hard to finish. To his, and Bella's amazement he is able to stop after sucking the poison out. James is subsequently ripped apart and burned by Emmett Cullen and Jasper Hale, Edward's brothers. Bella is then taken to a hospital in Phoenix, where she recovers from the attack. The story they ch...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 5 | Score: 0.0000\n",
      "üìö Libro: newmoon\n",
      "üìÑ Chunk #6\n",
      "üìè Palabras: 400\n",
      "üìù Texto: if she was a vampire, but she refuses. One of the leaders, Caius, states that Edward has still broken the law by revealing the vampire world to a human, violating the one rule of keeping the existence of vampires a secret. Therefore, they decree that Bella must be killed because she knows too much a...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üí¨ RESPUESTA BASADA EN CONTEXTO M√ÅS RELEVANTE:\n",
      "1 Bella Swan moves from Phoenix, Arizona to the small town of Forks, Washington, to live with her father, Charlie. She soon notices the mysterious Cullen family at school, who seem pale, beautiful, and distant from everyone else. 2 Edward Cullen, one of the Cullens, saves Bella from being crushed by a van with inhuman speed and strength. This event leads Bella to suspect that he is not an ordinary human. 3 Edward later reveals to Bella that he is a vampire. Despite the danger, they fall deeply i...\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üîé CONSULTA: 'Which Cullen family member is a doctor?'\n",
      "================================================================================\n",
      "\n",
      "üèÜ RANK 1 | Score: 0.1298\n",
      "üìö Libro: data_summary\n",
      "üìÑ Chunk #1\n",
      "üìè Palabras: 400\n",
      "üìù Texto: 1 Bella Swan moves from Phoenix, Arizona to the small town of Forks, Washington, to live with her father, Charlie. She soon notices the mysterious Cullen family at school, who seem pale, beautiful, and distant from everyone else. 2 Edward Cullen, one of the Cullens, saves Bella from being crushed by...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 2 | Score: 0.0529\n",
      "üìö Libro: twilight\n",
      "üìÑ Chunk #2\n",
      "üìè Palabras: 400\n",
      "üìù Texto: believes that they are vampires, though he doesn't think so. During a trip to Port Angeles, Edward rescues her again, this time from a band of serial rapists and killers. Bella asks him if what Jacob said about his family is true. Edward admits that he and his family are vampires, but says that he a...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 3 | Score: 0.0408\n",
      "üìö Libro: newmoon\n",
      "üìÑ Chunk #2\n",
      "üìè Palabras: 400\n",
      "üìù Texto: the world altogether. She feels this way, not only because she has lost her true love, but because his disappearance has triggered the irrational thought that he never existed in Bella's life. As her condition gradually worsens, Charlie begins to worry. When her father threatens to send her to live ...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 4 | Score: 0.0405\n",
      "üìö Libro: newmoon\n",
      "üìÑ Chunk #1\n",
      "üìè Palabras: 400\n",
      "üìù Texto: In the beginning of the book, Bella is upset because it's her birthday and it will make her older than the immortal 17-year-old Edward Cullen. Much to her dismay, the Cullen family throws her a birthday party. She then receives a present from Alice and Edward: a CD with Bella's lullaby on it. At the...\n",
      "--------------------------------------------------------------------------------\n",
      "üèÜ RANK 5 | Score: 0.0344\n",
      "üìö Libro: breakingdawn_bookthree\n",
      "üìÑ Chunk #3\n",
      "üìè Palabras: 400\n",
      "üìù Texto: anymore than he needs to know. This allows Bella to keep him in her new life and allows Charlie to go on with his life. Peace lasts for several months, but then things start to unravel again; Irina, a vampire from the Denali clan, sees Renesmee while hunting with Bella and Jacob and informs the Volt...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üí¨ RESPUESTA BASADA EN CONTEXTO M√ÅS RELEVANTE:\n",
      "1 Bella Swan moves from Phoenix, Arizona to the small town of Forks, Washington, to live with her father, Charlie. She soon notices the mysterious Cullen family at school, who seem pale, beautiful, and distant from everyone else. 2 Edward Cullen, one of the Cullens, saves Bella from being crushed by a van with inhuman speed and strength. This event leads Bella to suspect that he is not an ordinary human. 3 Edward later reveals to Bella that he is a vampire. Despite the danger, they fall deeply i...\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üìä Comparaci√≥n de m√©tricas Base vs Modelo B vs Modelo C\n",
      "                                     query  recall_base  precision_base  \\\n",
      "0            Who saves Bella from the van?     0.333333             0.2   \n",
      "1  Which Cullen family member is a doctor?     0.333333             0.2   \n",
      "\n",
      "   recall_model_b  precision_model_b  recall_model_c  precision_model_c  \n",
      "0        0.333333                0.2        0.666667                0.4  \n",
      "1        0.333333                0.2        0.333333                0.2  \n",
      "\n",
      "üìä Generando visualizaciones...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NOTEBOOK COMPLETO: Evaluaci√≥n RAG con respuestas estilo chat\n",
    "# ============================================================\n",
    "\n",
    "# ===================================\n",
    "# 1. Setup y dependencias\n",
    "# ===================================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from utils import load_chunks_from_folder\n",
    "from models.model_b import RAGModelB\n",
    "from models.model_c import RAGModelC\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar clave\n",
    "print(\"üîë Clave cargada:\", bool(os.getenv(\"AZURE_OPENAI_API_KEY\")))\n",
    "\n",
    "# Conexi√≥n a Azure OpenAI\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"https://pnl-maestria.openai.azure.com/\"\n",
    ")\n",
    "\n",
    "# Paths\n",
    "project_root = os.path.abspath(\"..\")\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "print(\"‚úÖ Project root:\", project_root)\n",
    "\n",
    "# ===================================\n",
    "# 2. Cargar chunks e √≠ndice TF-IDF (Modelo Base)\n",
    "# ===================================\n",
    "BASE_PREPROCESSED = os.path.join(project_root, \"data\", \"preprocessed\")\n",
    "folders = sorted([\n",
    "    os.path.join(BASE_PREPROCESSED, f)\n",
    "    for f in os.listdir(BASE_PREPROCESSED)\n",
    "    if f.startswith(\"processed_\")\n",
    "])\n",
    "\n",
    "records = []\n",
    "for folder in folders:\n",
    "    recs = load_chunks_from_folder(folder)\n",
    "    records.extend(recs)\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "documents = df[\"text\"].astype(str).tolist()\n",
    "print(f\"üìÑ Total chunks cargados: {len(documents)}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(f\"‚úÖ √çndice TF-IDF recreado: {X.shape[0]} documentos, {X.shape[1]} features\")\n",
    "\n",
    "# ===================================\n",
    "# 3. Funciones de evaluaci√≥n\n",
    "# ===================================\n",
    "@lru_cache(maxsize=128)\n",
    "def get_similarities_cached(query, k=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    top_k_scores = similarities[top_k_indices]\n",
    "    return tuple(top_k_indices), tuple(top_k_scores)\n",
    "\n",
    "def recall_at_k(top_k_indices, relevant_indices):\n",
    "    if not relevant_indices:\n",
    "        return 0.0\n",
    "    hits = len(set(top_k_indices) & set(relevant_indices))\n",
    "    return hits / len(relevant_indices)\n",
    "\n",
    "def precision_at_k(top_k_indices, relevant_indices, k=5):\n",
    "    if not relevant_indices:\n",
    "        return 0.0\n",
    "    hits = len(set(top_k_indices) & set(relevant_indices))\n",
    "    return hits / k\n",
    "\n",
    "def average_context_size(retrieved_indices, documents):\n",
    "    chunks = [documents[i] for i in retrieved_indices]\n",
    "    sizes = [len(c.split()) for c in chunks]\n",
    "    return np.mean(sizes) if sizes else 0\n",
    "\n",
    "def search_tfidf(query, k=5):\n",
    "    indices, scores = get_similarities_cached(query, k)\n",
    "    return list(indices), list(scores)\n",
    "\n",
    "# ===================================\n",
    "# 4. Ground truth\n",
    "# ===================================\n",
    "def find_relevant_chunks_fast(keyword_list, documents, max_chunks=3):\n",
    "    relevant = []\n",
    "    keywords_lower = [kw.lower() for kw in keyword_list]\n",
    "    for i, doc in enumerate(documents):\n",
    "        if len(relevant) >= max_chunks:\n",
    "            break\n",
    "        doc_lower = doc.lower()\n",
    "        if any(kw in doc_lower for kw in keywords_lower):\n",
    "            relevant.append(i)\n",
    "    return relevant\n",
    "\n",
    "queries = [\n",
    "    \"Who saves Bella from the van?\",\n",
    "    \"Which Cullen family member is a doctor?\",\n",
    "]\n",
    "\n",
    "keywords_per_query = [\n",
    "    [\"edward\", \"van\", \"save\"],\n",
    "    [\"carlisle\", \"doctor\"],\n",
    "]\n",
    "\n",
    "print(f\"\\nüîç Consultas definidas: {len(queries)}\")\n",
    "print(\"\\nü§ñ Generando ground truth autom√°tico...\")\n",
    "ground_truth = []\n",
    "for i, keywords in enumerate(keywords_per_query):\n",
    "    relevant = find_relevant_chunks_fast(keywords, documents, max_chunks=3)\n",
    "    ground_truth.append(relevant)\n",
    "    print(f\"Query {i+1}: {len(relevant)} chunks relevantes\")\n",
    "\n",
    "# ===================================\n",
    "# 5. Evaluaci√≥n con generaci√≥n estilo chat\n",
    "# ===================================\n",
    "def evaluate_with_chat(queries, ground_truth, documents, k=5):\n",
    "    recalls, precisions, context_sizes, all_responses = [], [], [], []\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        retrieved_indices, scores = search_tfidf(query, k=k)\n",
    "        recall = recall_at_k(retrieved_indices, ground_truth[i])\n",
    "        precision = precision_at_k(retrieved_indices, ground_truth[i], k=k)\n",
    "        context_size = average_context_size(retrieved_indices, documents)\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        context_sizes.append(context_size)\n",
    "\n",
    "        context = \"\\n\".join([documents[j] for j in retrieved_indices])\n",
    "        prompt = f\"\"\"\n",
    "You are a knowledgeable assistant who knows the Twilight Saga.\n",
    "Answer naturally, briefly, like in a chat.\n",
    "Use the context below ONLY if it contains the answer.\n",
    "If the answer is not in the context, just say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        generated_answer = response.choices[0].message.content.strip()\n",
    "\n",
    "        all_responses.append({\n",
    "            \"query\": query,\n",
    "            \"retrieved_indices\": retrieved_indices,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"context_size\": context_size,\n",
    "            \"answer\": generated_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"recall\": np.mean(recalls),\n",
    "        \"precision\": np.mean(precisions),\n",
    "        \"context_size\": np.mean(context_sizes),\n",
    "        \"details\": all_responses,\n",
    "        \"recalls\": recalls,\n",
    "        \"precisions\": precisions,\n",
    "        \"context_sizes\": context_sizes\n",
    "    }\n",
    "\n",
    "# Evaluaci√≥n Modelo Base\n",
    "results_base = evaluate_with_chat(queries, ground_truth, documents, k=5)\n",
    "\n",
    "# ===================================\n",
    "# 6. Evaluaci√≥n Modelo B\n",
    "# ===================================\n",
    "model_b = RAGModelB(\n",
    "    preprocessed_base_dir=os.path.join(project_root, \"data\", \"preprocessed\"),\n",
    "    similarity_threshold=0.75\n",
    ")\n",
    "model_b.prepare_documents(chunk_config=\"processed_400_100\")\n",
    "\n",
    "def evaluate_model_b_chat(model, queries, ground_truth, k=5):\n",
    "    recalls, precisions, context_sizes, all_responses = [], [], [], []\n",
    "    for i, query in enumerate(queries):\n",
    "        retrieved = model.query(query, top_k=k)\n",
    "        retrieved_indices = [idx_meta.get('chunk_number', 0) for _, _, idx_meta in retrieved]\n",
    "\n",
    "        recall = recall_at_k(retrieved_indices, ground_truth[i])\n",
    "        precision = precision_at_k(retrieved_indices, ground_truth[i], k=k)\n",
    "        context_size = np.mean([len(chunk.split()) for chunk, _, _ in retrieved]) if retrieved else 0\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        context_sizes.append(context_size)\n",
    "\n",
    "        context = \"\\n\".join([chunk for chunk, _, _ in retrieved])\n",
    "        prompt = f\"\"\"\n",
    "You are a knowledgeable assistant who knows the Twilight Saga.\n",
    "Answer naturally, briefly, like in a chat.\n",
    "Use the context below ONLY if it contains the answer.\n",
    "If the answer is not in the context, just say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        generated_answer = response.choices[0].message.content.strip()\n",
    "\n",
    "        all_responses.append({\n",
    "            \"query\": query,\n",
    "            \"retrieved_indices\": retrieved_indices,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"context_size\": context_size,\n",
    "            \"answer\": generated_answer\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"recall\": np.mean(recalls),\n",
    "        \"precision\": np.mean(precisions),\n",
    "        \"context_size\": np.mean(context_sizes),\n",
    "        \"details\": all_responses,\n",
    "        \"recalls\": recalls,\n",
    "        \"precisions\": precisions,\n",
    "        \"context_sizes\": context_sizes\n",
    "    }\n",
    "\n",
    "results_b = evaluate_model_b_chat(model_b, queries, ground_truth, k=5)\n",
    "\n",
    "# ===================================\n",
    "# 7. Evaluaci√≥n Modelo C\n",
    "# ===================================\n",
    "model_c = RAGModelC(\n",
    "    preprocessed_base_dir=os.path.join(project_root, \"data\", \"preprocessed\"),\n",
    "    similarity_threshold=0.85\n",
    ")\n",
    "model_c.prepare_documents(chunk_config=\"processed_400_100\")\n",
    "results_c = evaluate_model_b_chat(model_c, queries, ground_truth, k=5)\n",
    "\n",
    "# ===================================\n",
    "# 8. Comparaci√≥n resultados Base vs B vs C\n",
    "# ===================================\n",
    "summary_df = pd.DataFrame({\n",
    "    \"query\": [r[\"query\"] for r in results_base[\"details\"]],\n",
    "    \"recall_base\": results_base['recalls'],\n",
    "    \"precision_base\": results_base['precisions'],\n",
    "    \"recall_model_b\": results_b['recalls'],\n",
    "    \"precision_model_b\": results_b['precisions'],\n",
    "    \"recall_model_c\": results_c['recalls'],\n",
    "    \"precision_model_c\": results_c['precisions'],\n",
    "})\n",
    "print(\"\\nüìä Comparaci√≥n de m√©tricas Base vs Modelo B vs Modelo C\")\n",
    "print(summary_df)\n",
    "\n",
    "# ===================================\n",
    "# 9. Visualizaci√≥n (igual que antes)\n",
    "# ===================================\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    matplotlib.use('TkAgg')\n",
    "    \n",
    "    print(\"\\nüìä Generando visualizaciones...\")\n",
    "    \n",
    "    query_labels = [f\"Q{i+1}\" for i in range(len(queries))]\n",
    "    width = 0.2\n",
    "    x = np.arange(len(queries))\n",
    "    \n",
    "    # Recall\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.bar(x - width, results_base['recalls'], width, label='Base', color='#2ecc71')\n",
    "    ax.bar(x, results_b['recalls'], width, label='Modelo B', color='#3498db')\n",
    "    ax.bar(x + width, results_c['recalls'], width, label='Modelo C', color='#e74c3c')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(query_labels)\n",
    "    ax.set_ylabel('Recall@5')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title('Comparaci√≥n Recall@5 por Consulta', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(project_root, 'data', 'comparison_recall.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Precision\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    ax.bar(x - width, results_base['precisions'], width, label='Base', color='#2ecc71')\n",
    "    ax.bar(x, results_b['precisions'], width, label='Modelo B', color='#3498db')\n",
    "    ax.bar(x + width, results_c['precisions'], width, label='Modelo C', color='#e74c3c')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(query_labels)\n",
    "    ax.set_ylabel('Precision@5')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title('Comparaci√≥n Precision@5 por Consulta', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(project_root, 'data', 'comparison_precision.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n matplotlib no disponible. Instalar con: pip install matplotlib\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error en visualizaci√≥n: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cd9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e5bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
