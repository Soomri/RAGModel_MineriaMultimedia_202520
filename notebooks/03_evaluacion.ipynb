{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012ff87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Clave cargada: True\n",
      "‚úÖ Project root: c:\\Users\\USER\\RAGModel_MineriaMultimedia_202520\n",
      "üìÑ Total chunks cargados: 66\n",
      "‚úÖ √çndice TF-IDF recreado: 66 documentos, 1538 features\n",
      "\n",
      "üîç Consultas definidas: 2\n",
      "\n",
      "ü§ñ Generando ground truth autom√°tico...\n",
      "Query 1: 3 chunks relevantes\n",
      "Query 2: 3 chunks relevantes\n",
      "\n",
      "================================================================================\n",
      "EVALUACI√ìN DEL SISTEMA RAG (RETRIEVAL + GENERACI√ìN)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üîé CONSULTA 1: 'Who saves Bella from the van?'\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS RETRIEVAL:\n",
      "  ‚Ä¢ Recall@5:    0.333\n",
      "  ‚Ä¢ Precision@5: 0.200\n",
      "  ‚Ä¢ Contexto:      625.8 palabras\n",
      "\n",
      "üß† RESPUESTA GENERADA POR EL MODELO:\n",
      "Edward Cullen saves Bella from the van.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "üîé CONSULTA 2: 'Which Cullen family member is a doctor?'\n",
      "================================================================================\n",
      "\n",
      "üìä M√âTRICAS RETRIEVAL:\n",
      "  ‚Ä¢ Recall@5:    0.333\n",
      "  ‚Ä¢ Precision@5: 0.200\n",
      "  ‚Ä¢ Contexto:      640.0 palabras\n",
      "\n",
      "üß† RESPUESTA GENERADA POR EL MODELO:\n",
      "Carlisle Cullen is the family member who is a doctor.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "üìà RESULTADOS PROMEDIO\n",
      "================================================================================\n",
      "Recall@5:    0.333\n",
      "Precision@5: 0.200\n",
      "Contexto:      632.9 palabras\n",
      "================================================================================\n",
      "\n",
      "‚è±Ô∏è Tiempo total de evaluaci√≥n: 2.12 segundos\n",
      "\n",
      "‚úÖ Resultados guardados en: c:\\Users\\USER\\RAGModel_MineriaMultimedia_202520\\data\\evaluation_results_rag.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ EVALUACI√ìN COMPLETADA (RAG CON AZURE OPENAI)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 03 - Evaluaci√≥n del Sistema RAG (CON VISUALIZACI√ìN DE RESPUESTAS Y GENERACI√ìN)\n",
    "# =============================================================================\n",
    "\n",
    "# ===================================\n",
    "# 1. Setup y carga de dependencias\n",
    "# ===================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import lru_cache\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Verifica que las variables se cargaron\n",
    "print(\"üîë Clave cargada:\", bool(os.getenv(\"AZURE_OPENAI_API_KEY\")))\n",
    "\n",
    "# üîπ Conexi√≥n a Azure OpenAI\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"https://pnl-maestria.openai.azure.com/\"\n",
    ")\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys_path = os.path.join(project_root, \"src\")\n",
    "if sys_path not in sys.path:\n",
    "    sys.path.append(sys_path)\n",
    "\n",
    "print(\"‚úÖ Project root:\", project_root)\n",
    "\n",
    "# ===================================\n",
    "# 2. Cargar datos e √≠ndice TF-IDF\n",
    "# ===================================\n",
    "\n",
    "from utils import load_chunks_from_folder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "BASE_PREPROCESSED = os.path.join(project_root, \"data\", \"preprocessed\")\n",
    "folders = sorted([\n",
    "    os.path.join(BASE_PREPROCESSED, f)\n",
    "    for f in os.listdir(BASE_PREPROCESSED)\n",
    "    if f.startswith(\"processed_\")\n",
    "])\n",
    "\n",
    "records = []\n",
    "for folder in folders:\n",
    "    recs = load_chunks_from_folder(folder)\n",
    "    records.extend(recs)\n",
    "\n",
    "df = pd.DataFrame.from_records(records)\n",
    "documents = df[\"text\"].astype(str).tolist()\n",
    "\n",
    "print(f\"üìÑ Total chunks cargados: {len(documents)}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"‚úÖ √çndice TF-IDF recreado: {X.shape[0]} documentos, {X.shape[1]} features\")\n",
    "\n",
    "# ===================================\n",
    "# 3. Funciones de evaluaci√≥n\n",
    "# ===================================\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def get_similarities_cached(query, k=5):\n",
    "    query_vec = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vec, X).flatten()\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    top_k_scores = similarities[top_k_indices]\n",
    "    return tuple(top_k_indices), tuple(top_k_scores)\n",
    "\n",
    "\n",
    "def recall_at_k(top_k_indices, relevant_indices):\n",
    "    if not relevant_indices:\n",
    "        return 0.0\n",
    "    hits = len(set(top_k_indices) & set(relevant_indices))\n",
    "    return hits / len(relevant_indices)\n",
    "\n",
    "\n",
    "def precision_at_k(top_k_indices, relevant_indices, k=5):\n",
    "    if not relevant_indices:\n",
    "        return 0.0\n",
    "    hits = len(set(top_k_indices) & set(relevant_indices))\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def average_context_size(retrieved_indices, documents):\n",
    "    chunks = [documents[i] for i in retrieved_indices]\n",
    "    sizes = [len(c.split()) for c in chunks]\n",
    "    return np.mean(sizes) if sizes else 0\n",
    "\n",
    "\n",
    "def search_tfidf(query, k=5):\n",
    "    indices, scores = get_similarities_cached(query, k)\n",
    "    return list(indices), list(scores)\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# 4. Ground truth\n",
    "# ===================================\n",
    "\n",
    "def find_relevant_chunks_fast(keyword_list, documents, max_chunks=3):\n",
    "    relevant = []\n",
    "    keywords_lower = [kw.lower() for kw in keyword_list]\n",
    "\n",
    "    for i, doc in enumerate(documents):\n",
    "        if len(relevant) >= max_chunks:\n",
    "            break\n",
    "        doc_lower = doc.lower()\n",
    "        if any(kw in doc_lower for kw in keywords_lower):\n",
    "            relevant.append(i)\n",
    "\n",
    "    return relevant\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# 5. Definir consultas\n",
    "# ===================================\n",
    "\n",
    "queries = [\n",
    "    \"Who saves Bella from the van?\",\n",
    "    \"Which Cullen family member is a doctor?\",\n",
    "]\n",
    "\n",
    "keywords_per_query = [\n",
    "    [\"edward\", \"van\", \"save\"],\n",
    "    [\"carlisle\", \"doctor\"],\n",
    "]\n",
    "\n",
    "print(f\"\\nüîç Consultas definidas: {len(queries)}\")\n",
    "print(\"\\nü§ñ Generando ground truth autom√°tico...\")\n",
    "ground_truth = []\n",
    "for i, keywords in enumerate(keywords_per_query):\n",
    "    relevant = find_relevant_chunks_fast(keywords, documents, max_chunks=3)\n",
    "    ground_truth.append(relevant)\n",
    "    print(f\"Query {i+1}: {len(relevant)} chunks relevantes\")\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# 6. Evaluaci√≥n con visualizaci√≥n + generaci√≥n RAG\n",
    "# ===================================\n",
    "\n",
    "def evaluate_with_generation(queries, ground_truth, documents, k=5):\n",
    "    recalls, precisions, context_sizes, all_responses = [], [], [], []\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EVALUACI√ìN DEL SISTEMA RAG (RETRIEVAL + GENERACI√ìN)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üîé CONSULTA {i+1}: '{query}'\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        # --- Recuperaci√≥n\n",
    "        retrieved_indices, scores = search_tfidf(query, k=k)\n",
    "        recall = recall_at_k(retrieved_indices, ground_truth[i])\n",
    "        precision = precision_at_k(retrieved_indices, ground_truth[i], k=k)\n",
    "        context_size = average_context_size(retrieved_indices, documents)\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "        context_sizes.append(context_size)\n",
    "\n",
    "        print(f\"\\nüìä M√âTRICAS RETRIEVAL:\")\n",
    "        print(f\"  ‚Ä¢ Recall@{k}:    {recall:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Precision@{k}: {precision:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Contexto:      {context_size:.1f} palabras\")\n",
    "\n",
    "        # --- Construir contexto para el modelo\n",
    "        context = \"\\n\".join([documents[j] for j in retrieved_indices])\n",
    "        prompt = f\"\"\"\n",
    "        You are a knowledgeable assistant.\n",
    "        Use the following context to answer the question concisely and accurately.\n",
    "        If the answer is not in the context, say you don‚Äôt know.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Generaci√≥n con Azure OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-nano\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        generated_answer = response.choices[0].message.content.strip()\n",
    "\n",
    "        print(\"\\nüß† RESPUESTA GENERADA POR EL MODELO:\")\n",
    "        print(generated_answer)\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        all_responses.append({\n",
    "            \"query\": query,\n",
    "            \"retrieved_indices\": retrieved_indices,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"context_size\": context_size,\n",
    "            \"answer\": generated_answer\n",
    "        })\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà RESULTADOS PROMEDIO\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Recall@{k}:    {np.mean(recalls):.3f}\")\n",
    "    print(f\"Precision@{k}: {np.mean(precisions):.3f}\")\n",
    "    print(f\"Contexto:      {np.mean(context_sizes):.1f} palabras\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return {\n",
    "        \"recall\": np.mean(recalls),\n",
    "        \"precision\": np.mean(precisions),\n",
    "        \"context_size\": np.mean(context_sizes),\n",
    "        \"details\": all_responses\n",
    "    }\n",
    "\n",
    "\n",
    "# ===================================\n",
    "# 7. Ejecutar evaluaci√≥n completa (RAG)\n",
    "# ===================================\n",
    "\n",
    "start_time = time.time()\n",
    "results = evaluate_with_generation(\n",
    "    queries=queries,\n",
    "    ground_truth=ground_truth,\n",
    "    documents=documents,\n",
    "    k=5\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n‚è±Ô∏è Tiempo total de evaluaci√≥n: {elapsed_time:.2f} segundos\")\n",
    "\n",
    "# ===================================\n",
    "# 8. Guardar resultados\n",
    "# ===================================\n",
    "\n",
    "results_df = pd.DataFrame([{\n",
    "    \"query\": r[\"query\"],\n",
    "    \"recall\": r[\"recall\"],\n",
    "    \"precision\": r[\"precision\"],\n",
    "    \"context_size\": r[\"context_size\"],\n",
    "    \"generated_answer\": r[\"answer\"]\n",
    "} for r in results[\"details\"]])\n",
    "\n",
    "output_path = os.path.join(project_root, \"data\", \"evaluation_results_rag.csv\")\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n‚úÖ Resultados guardados en: {output_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ EVALUACI√ìN COMPLETADA (RAG CON AZURE OPENAI)\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cd9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e5bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
