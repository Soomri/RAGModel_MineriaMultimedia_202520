{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42269565",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c75c7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def recall_at_k(query_vector, X, relevant_indices, k=5):\n",
    "    \"\"\"\n",
    "    Calcula el recall@k dado un vector de consulta y una matriz TF-IDF.\n",
    "    \"\"\"\n",
    "    similarities = cosine_similarity(query_vector, X).flatten()\n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    hits = len(set(top_k_indices) & set(relevant_indices))\n",
    "    recall = hits / len(relevant_indices) if relevant_indices else 0\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe16eb4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def average_context_size(chunks):\n",
    "    \"\"\"\n",
    "    Calcula el tamaÃ±o medio (en palabras) de los chunks recuperados.\n",
    "    \"\"\"\n",
    "    sizes = [len(c.split()) for c in chunks]\n",
    "    return np.mean(sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c68fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, queries, ground_truth):\n",
    "    \"\"\"\n",
    "    EvalÃºa el modelo RAG con varias consultas.\n",
    "    - queries: lista de textos de consulta.\n",
    "    - ground_truth: lista de Ã­ndices relevantes por consulta.\n",
    "    \"\"\"\n",
    "    recalls, context_sizes = [], []\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\nðŸ”Ž Evaluando consulta {i+1}: {query}\")\n",
    "        results = model.query(query, top_k=5)\n",
    "        retrieved_chunks = [r[0] for r in results]\n",
    "        recall = recall_at_k(\n",
    "            model.vectorizer.transform([query]),\n",
    "            model.X,\n",
    "            ground_truth[i],\n",
    "            k=5,\n",
    "        )\n",
    "        recalls.append(recall)\n",
    "        context_sizes.append(average_context_size(retrieved_chunks))\n",
    "\n",
    "    avg_recall = np.mean(recalls)\n",
    "    avg_context = np.mean(context_sizes)\n",
    "\n",
    "    print(\"\\nðŸ“ˆ Resultados promedio:\")\n",
    "    print(f\"Recall@5 promedio: {avg_recall:.3f}\")\n",
    "    print(f\"TamaÃ±o medio de contexto: {avg_context:.1f} palabras\")\n",
    "\n",
    "    return avg_recall, avg_context"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
